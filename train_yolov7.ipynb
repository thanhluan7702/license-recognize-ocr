{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24102,"status":"ok","timestamp":1671278752681,"user":{"displayName":"training colab1","userId":"07051642483341372615"},"user_tz":-420},"id":"1LSY12gjDFly","outputId":"9f27a506-01b0-4ee9-8934-e0bd00bf562c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDa6UqvIDj5j"},"outputs":[],"source":["# # clone yolov7 from github \n","\n","# %cd /content/drive/MyDrive\n","# !mkdir yolov7_train \n","# %cd yolov7_train\n","# !git clone https://github.com/augmentedstartups/yolov7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uNcoeVLlDl3G"},"outputs":[],"source":["# # install library require \n","\n","# %cd /content/drive/MyDrive/yolov7_train/yolov7\n","# !pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"poWVB-BwDpRP"},"outputs":[],"source":["# # download weight file \n","\n","# %cd /content/drive/MyDrive/yolov7_train/yolov7\n","# !mkdir pretrain \n","# %cd pretrain \n","# !wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7x.pt"]},{"cell_type":"markdown","metadata":{"id":"QUv3_Ys-D2g6"},"source":["# Train model "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1671246636069,"user":{"displayName":"training colab1","userId":"07051642483341372615"},"user_tz":-420},"id":"zf0X3hmXDuEn","outputId":"83a7f4d7-b256-4ea7-8fcf-c7797c1747d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/yolov7_train\n"]}],"source":["# # clone data for train model \n","\n","# %cd /content/drive/MyDrive/yolov7_train\n","# !mkdir train_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":873,"status":"ok","timestamp":1671246661334,"user":{"displayName":"training colab1","userId":"07051642483341372615"},"user_tz":-420},"id":"IKjK1dZ4D9-m","outputId":"fe29087b-32cc-4bfb-d15f-7ec8a5f4865f"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/yolov7_train/train_data\n"]}],"source":["# %cd /content/drive/MyDrive/yolov7_train/train_data\n","# !mkdir train\n","# !mkdir train/images\n","# !mkdir train/labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27598,"status":"ok","timestamp":1671250026556,"user":{"displayName":"training colab1","userId":"07051642483341372615"},"user_tz":-420},"id":"E1VpHfqAEEAP","outputId":"cde6c015-d862-47d5-a2dd-67930c80c8be"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/yolov7_train/train_data/train/labels\n"]}],"source":["# # create label \n","# %cd /content/drive/MyDrive/yolov7_train/train_data/train/labels\n","\n","# import pandas as pd\n","# import glob \n","\n","# for label in glob.glob('*.txt'): \n","#   location = list(pd.read_csv(label, sep = \" \", on_bad_lines='skip').columns)\n","#   location[0] = '0'\n","#   with open(label, 'w') as f: \n","#     for idx, coor in enumerate(location):\n","#       if idx != 4:\n","#         f.write(coor)\n","#         f.write(\" \") \n","#       else: \n","#         f.write(coor)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1096,"status":"ok","timestamp":1671250079822,"user":{"displayName":"training colab1","userId":"07051642483341372615"},"user_tz":-420},"id":"ZI4rQ8gwEGoW","outputId":"521053d3-4677-4895-e979-0d77ce81a1cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/yolov7_train/yolov7\n"]}],"source":["# # Khai bÃ¡o 1 file yaml Ä‘á»ƒ YOLOv7 biáº¿t:\n","# # - ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c train, test (náº¿u cÃ³, náº¿u khÃ´ng thÃ¬ dÃ¹ng luÃ´n Ä‘Æ°á»ng dáº«n Ä‘áº¿n train)\n","# # - Sá»‘ lÆ°á»£ng class qua biáº¿n nc (number of class)\n","# # - TÃªn cá»§a cÃ¡c class\n","\n","# %cd /content/drive/MyDrive/yolov7_train/yolov7\n","# # !rm data/mydataset.yaml # if exist\n","# !echo 'train: ../train_data/train' >> data/mydataset.yaml\n","# !echo 'val: ../train_data/train' >> data/mydataset.yaml\n","# !echo 'nc: 1' >> data/mydataset.yaml\n","# !echo \"names: ['license plate']\" >> data/mydataset.yaml"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2010608,"status":"ok","timestamp":1671280767790,"user":{"displayName":"training colab1","userId":"07051642483341372615"},"user_tz":-420},"id":"8OAnCLx0EGqV","outputId":"decde8c4-f87d-4c16-d5c2-7316ac5bc420"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/yolov7_train/yolov7\n","YOLOR ðŸš€ v0.1-105-gfe0f0eb torch 1.13.0+cu116 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=False, cfg='cfg/training/yolov7x.yaml', data='data/mydataset.yaml', device='', entity=None, epochs=10, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='pretrain/yolov7x.pt', workers=8, world_size=1)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      1160  models.common.Conv                      [3, 40, 3, 1]                 \n","  1                -1  1     28960  models.common.Conv                      [40, 80, 3, 2]                \n","  2                -1  1     57760  models.common.Conv                      [80, 80, 3, 1]                \n","  3                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n","  4                -1  1     10368  models.common.Conv                      [160, 64, 1, 1]               \n","  5                -2  1     10368  models.common.Conv                      [160, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 11                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 12[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    103040  models.common.Conv                      [320, 320, 1, 1]              \n"," 14                -1  1         0  models.common.MP                        []                            \n"," 15                -1  1     51520  models.common.Conv                      [320, 160, 1, 1]              \n"," 16                -3  1     51520  models.common.Conv                      [320, 160, 1, 1]              \n"," 17                -1  1    230720  models.common.Conv                      [160, 160, 3, 2]              \n"," 18          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 19                -1  1     41216  models.common.Conv                      [320, 128, 1, 1]              \n"," 20                -2  1     41216  models.common.Conv                      [320, 128, 1, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 24                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 25                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 26                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 27[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n"," 28                -1  1    410880  models.common.Conv                      [640, 640, 1, 1]              \n"," 29                -1  1         0  models.common.MP                        []                            \n"," 30                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n"," 31                -3  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n"," 32                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n"," 33          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 34                -1  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n"," 35                -2  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n"," 36                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 37                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 38                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 39                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 40                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 41                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 42[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1   1640960  models.common.Conv                      [1280, 1280, 1, 1]            \n"," 44                -1  1         0  models.common.MP                        []                            \n"," 45                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n"," 46                -3  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n"," 47                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n"," 48          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 49                -1  1    328192  models.common.Conv                      [1280, 256, 1, 1]             \n"," 50                -2  1    328192  models.common.Conv                      [1280, 256, 1, 1]             \n"," 51                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 52                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 53                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 54                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 55                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 56                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 57[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n"," 58                -1  1   1640960  models.common.Conv                      [1280, 1280, 1, 1]            \n"," 59                -1  1  11887360  models.common.SPPCSPC                   [1280, 640, 1]                \n"," 60                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n"," 61                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 62                43  1    410240  models.common.Conv                      [1280, 320, 1, 1]             \n"," 63          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 64                -1  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n"," 65                -2  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n"," 66                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 67                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 68                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 69                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 70                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 71                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 72[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n"," 73                -1  1    410240  models.common.Conv                      [1280, 320, 1, 1]             \n"," 74                -1  1     51520  models.common.Conv                      [320, 160, 1, 1]              \n"," 75                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 76                28  1    102720  models.common.Conv                      [640, 160, 1, 1]              \n"," 77          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 78                -1  1     41216  models.common.Conv                      [320, 128, 1, 1]              \n"," 79                -2  1     41216  models.common.Conv                      [320, 128, 1, 1]              \n"," 80                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 81                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 82                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 83                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n"," 87                -1  1    102720  models.common.Conv                      [640, 160, 1, 1]              \n"," 88                -1  1         0  models.common.MP                        []                            \n"," 89                -1  1     25920  models.common.Conv                      [160, 160, 1, 1]              \n"," 90                -3  1     25920  models.common.Conv                      [160, 160, 1, 1]              \n"," 91                -1  1    230720  models.common.Conv                      [160, 160, 3, 2]              \n"," 92      [-1, -3, 73]  1         0  models.common.Concat                    [1]                           \n"," 93                -1  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n"," 94                -2  1    164352  models.common.Conv                      [640, 256, 1, 1]              \n"," 95                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 96                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","101[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n","102                -1  1    410240  models.common.Conv                      [1280, 320, 1, 1]             \n","103                -1  1         0  models.common.MP                        []                            \n","104                -1  1    103040  models.common.Conv                      [320, 320, 1, 1]              \n","105                -3  1    103040  models.common.Conv                      [320, 320, 1, 1]              \n","106                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n","107      [-1, -3, 59]  1         0  models.common.Concat                    [1]                           \n","108                -1  1    656384  models.common.Conv                      [1280, 512, 1, 1]             \n","109                -2  1    656384  models.common.Conv                      [1280, 512, 1, 1]             \n","110                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n","111                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n","112                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n","113                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n","114                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n","115                -1  1   2360320  models.common.Conv                      [512, 512, 3, 1]              \n","116[-1, -3, -5, -7, -8]  1         0  models.common.Concat                    [1]                           \n","117                -1  1   1639680  models.common.Conv                      [2560, 640, 1, 1]             \n","118                87  1    461440  models.common.Conv                      [160, 320, 3, 1]              \n","119               102  1   1844480  models.common.Conv                      [320, 640, 3, 1]              \n","120               117  1   7375360  models.common.Conv                      [640, 1280, 3, 1]             \n","121   [118, 119, 120]  1     42668  models.yolo.IDetect                     [1, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [320, 640, 1280]]\n","Model Summary: 467 layers, 70815092 parameters, 70815092 gradients\n","\n","Transferred 630/644 items from pretrain/yolov7x.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 108 .bias, 108 conv.weight, 111 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../train_data/train/labels.cache' images and labels... 1748 found, 0 missing, 0 empty, 1 corrupted: 100% 1748/1748 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '../train_data/train/labels.cache' images and labels... 1748 found, 0 missing, 0 empty, 1 corrupted: 100% 1748/1748 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 6.03, Best Possible Recall (BPR) = 1.0000\n","Image sizes 640 train, 640 test\n","Using 2 dataloader workers\n","Logging results to runs/train/exp\n","Starting training for 10 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       0/9     9.36G   0.06847    0.3284         0    0.3969         5       640: 100% 219/219 [03:38<00:00,  1.00it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95:   0% 0/110 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 110/110 [00:40<00:00,  2.72it/s]\n","                 all        1747        1747      0.0415        0.38      0.0315      0.0066\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       1/9     9.33G   0.04991  0.005684         0    0.0556         9       640: 100% 219/219 [02:27<00:00,  1.48it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 110/110 [00:32<00:00,  3.36it/s]\n","                 all        1747        1747       0.997           1       0.995        0.69\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       2/9     9.34G   0.03268  0.003216         0   0.03589        12       640: 100% 219/219 [02:26<00:00,  1.49it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 110/110 [00:33<00:00,  3.31it/s]\n","                 all        1747        1747       0.968       0.999        0.99       0.747\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       3/9     9.34G   0.03054  0.003062         0    0.0336         4       640: 100% 219/219 [02:26<00:00,  1.50it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 110/110 [00:32<00:00,  3.37it/s]\n","                 all        1747        1747       0.999           1       0.995        0.67\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       4/9     9.34G   0.02791  0.002982         0   0.03089         6       640: 100% 219/219 [02:24<00:00,  1.52it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 110/110 [00:32<00:00,  3.37it/s]\n","                 all        1747        1747           1           1       0.995       0.803\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       5/9     9.34G   0.02435  0.002692         0   0.02704        11       640: 100% 219/219 [02:25<00:00,  1.50it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 110/110 [00:32<00:00,  3.39it/s]\n","                 all        1747        1747           1           1       0.995        0.79\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       6/9     9.34G   0.01951  0.002476         0   0.02199         7       640: 100% 219/219 [02:25<00:00,  1.50it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 110/110 [00:32<00:00,  3.38it/s]\n","                 all        1747        1747           1           1       0.995       0.805\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       7/9     9.34G   0.01726  0.002223         0   0.01948         3       640: 100% 219/219 [02:26<00:00,  1.50it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 110/110 [00:32<00:00,  3.37it/s]\n","                 all        1747        1747           1           1       0.995       0.823\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       8/9     9.34G   0.01559  0.002111         0    0.0177         6       640: 100% 219/219 [02:25<00:00,  1.51it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 110/110 [00:33<00:00,  3.32it/s]\n","                 all        1747        1747           1           1       0.995       0.832\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       9/9     9.34G   0.01468  0.002058         0   0.01674         8       640: 100% 219/219 [02:26<00:00,  1.50it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 110/110 [00:34<00:00,  3.20it/s]\n","                 all        1747        1747           1           1       0.996       0.829\n","10 epochs completed in 0.537 hours.\n","\n","Optimizer stripped from runs/train/exp/weights/last.pt, 142.1MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 142.1MB\n"]}],"source":["# ## Train model YOLOv7 vá»›i dá»¯ liá»‡u license plate\n","\n","# ## v7:  1 1 0995 --> (converge : 50-60 epochs)\n","# ## v7x: 1 1 0995 --> (converge : 10 epochs)\n","\n","\n","# %cd /content/drive/MyDrive/yolov7_train/yolov7\n","# !python train.py --batch 8 --cfg cfg/training/yolov7x.yaml --epochs 10 --data data/mydataset.yaml --weights 'pretrain/yolov7x.pt'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYOeR-o0EKFK"},"outputs":[],"source":["# %cd /content/drive/MyDrive/yolov7_train/yolov7\n","\n","# # detect video\n","# !python detect.py --weights runs/train/exp/weights/best.pt --conf 0.25 --img-size 640 --source ../train_data/train/Licence_Plate_Camera_Illustration_Video.mp4\n","\n","# # detect image \n","# !python detect.py --weights runs/train/exp/weights/best.pt --conf 0.25 --img-size 640 --source ../train_data/train/images/0521_05656_b.jpg\n","# !python detect_and_crop.py --weights runs/train/exp/weights/best.pt --conf 0.25 --img-size 640 --source ../train_data/train/images/0521_05656_b.jpg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wxDJATD-Cd08"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNFFMDyFaGKkNTc0OptONAa","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
